# Teambot

Nous allons entre**prendre** un voyage qui vous permettra de vous √©**prendre** de l'Intelligence artificielle car nous allons cr√©er votre nouvel ami intelligent et cultiv√©, toujours disponible et bienveillant √†  votre √©gard. 
- Il va commencer par **prendre** toute sortes de donn√©es (texte, image, son, vid√©o...)
- Il va devoir les com**prendre** afin d'utiliser ce savoir pour vous ap**prendre** tout ce que vous souhaitez.   
- Pour nos enseignants, il leur faudra d√©sap**prendre** leurs m√©thodes traditionnelles comme l'apprentissage des langues ou de la programmation pour s'adapter √† ce nouvel outil. 
- Mais il ne faut pas vous m√©**prendre**, √† charge √† vous de re**prendre** le contr√¥le des op√©rations et nul doute que les r√©sultats ne manqueront pas de vous sur**prendre** !!! 

# Teambot : Cahier des charges

## Introduction

Le travail d'√©quipe peut largement √™tre am√©lior√© avec l'aide des derni√®res technologies informatiques :

- Les ¬´ Large Language Models ¬ª (LLM) ont des capacit√©s qui s'am√©liorent de jour en jour.
- Les GPU permettent des ex√©cutions ultra-rapides de t√¢ches complexes telles que les mod√©lisations 3D.

Cependant, il n'existe pas actuellement d'environnement permettant un travail collaboratif efficace et simple d'emploi. **Teambot** vise √† combler ce manque.

Ce document √©tablit le cahier des charges de Teambot et identifie les frameworks les plus pertinents pour sa mise en ≈ìuvre.

[solution concurrente](https://abacus.ai/chat_llm-ent)
  - ü§ñ Introduction de ChatLLM : une plateforme tout-en-un pour acc√©der √† plusieurs mod√®les de langage avanc√©s.
  - üìÑ Capacit√© √† t√©l√©charger et √† analyser des PDF et autres documents pour g√©n√©rer des graphiques et des analyses.
  - üîó Int√©gration avec des services tiers comme Slack et Google Drive pour plus de commodit√©.
  - üí¨ Cr√©ation de chatbots personnalis√©s et d'agents IA d√©ployables en production.
  - üåê Fonctionnalit√©s de recherche web, g√©n√©ration d'images, ex√©cution de code, et cr√©ation de graphiques.
  - üìä Utilisation de techniques de fine-tuning et de g√©n√©ration augment√©e pour construire des chatbots adapt√©s √† des bases de connaissances sp√©cifiques.
  - üßë‚Äçüíª √âquipe de d√©veloppement compos√©e d'ing√©nieurs logiciels, d'experts en apprentissage machine, et de consultants en IA pour fournir des solutions IA pour les entreprises et les usages personnels.
  - üÜì P√©riode d'essai gratuite d'un mois pour tester la plateforme avant de s'engager.

## Fonctionnalit√©s principales

### 1. Workspace de travail

- Un espace d√©di√© par projet, ouvert √† l'√©quipe charg√©e de sa mise en ≈ìuvre.
- Supervision des √©changes pour correspondre aux valeurs et objectifs de l'entreprise.

### 2. Conservation intelligente du projet

- Stockage des donn√©es brutes du projet.
- Possibilit√© d'interroger le projet en langage naturel pour obtenir des r√©ponses ad√©quates.

### 3. LLM local et open source

- Contr√¥le complet du fonctionnement.
- Conservation de la confidentialit√© lorsque n√©cessaire.
- Utilisation d'un prompt syst√®me.

### 4. M√©moire √† court terme importante

- Permet des √©changes entre les divers acteurs sans perte de connaissance.

### 5. Bot d√©di√© √† chaque membre de l'√©quipe

Chaque bot personnel dispose de :

- Un espace personnel accessible uniquement par l'utilisateur (stockage des donn√©es sur son PC).
  - Sert d'assistant personnel et d'outil de formation continue.
- Acc√®s aux donn√©es du projet pertinentes pour l'utilisateur.
- Acc√®s √† des outils sp√©cifiques pour faciliter les t√¢ches.
- Interface via l'√©crit ou la parole.

#### Capacit√©s du bot

Le bot doit pouvoir :

- **Prendre** des donn√©es :
  - Fichiers locaux
  - Speech-to-text
  - Image/vid√©o to text (en particulier vid√©os YouTube) :GPT-4o  devrait avoir cette capacit√© dans un avenir proche mais [des astuces sont possibles d√®s aujourd'hui](https://chatgpt.com/share/3afc20a8-ac01-410a-9288-0059c99780e9) 
  - Via internet (en particulier assimilation des codes disponibles sur Github)
    
- **Assimiler** les donn√©es :
  - Dans sa m√©moire √† court terme (contexte)
  - Dans sa m√©moire √† long terme (RAG)
  - Dans ses "g√®nes" (fine-tuning)
    
- **Activer** des ressources sp√©cifiques (function calling)
  
- **Cr√©er et utiliser des outils** soit disponible sur API (gorilla) soit qu'il cr√©e lui m√™me en cr√©ant le programme, en le lan√ßant et en it√©rant suivant les erreurs rencontr√©es. 
  
- **Cr√©er des agents** susceptibles de devenir experts dans un domaine donn√© gr√¢ce √† leur capacit√© d'apprentissage et √† leur ma√Ætrise d'outils d√©di√©s.

- **Exemple d'expertises utiles √† Teambot**:
  - [Expert en RAG](Generative AI/local-rag-ollama-mistral-chroma.py)
  - Expert en mod√©lisation Walk on Sph√®res pour l'optimisation d'objet 3D en √©lectrostatique, magn√©tostatique, Navier/Stokes , thermique ...;
  - Expert en ModelingToolkit (ModelingToolkit.jl est un cadre de mod√©lisation pour les calculs symboliques-num√©riques √† haute performance en informatique scientifique et en apprentissage automatique scientifique.) 
  - Expert en Grasshopper pour la mod√©lisation param√©trique d'objets complexes
  - Expert en pilotage de convertisseur par microprocesseur
  - Expert en jumeaux num√©riques
  - Expert en web scaping (comme perplexica)
  - [Expert en programmation](https://github.com/huangd1999/AgentCoder)
  - [Expert en optimisation inverse](https://github.com/AI4Science-WestlakeU/cindm)
  - [Expert en cr√©ation d'agent en tant que service](https://github.com/run-llama/llama-agents?tab=readme-ov-file)
  - ...

## Principes fondamentaux

- Le bot est un outil permettant un travail plus efficace, mais **pilot√© par l'homme qui en assure le contr√¥le et la pertinence**.
- Objectif : √©viter au mieux les hallucinations.

## Ressources mat√©rielles

- Implantation locale de Teambot sur un serveur.
- Accessible √† tout membre de l'√©quipe disposant des droits n√©cessaires, sans besoin de PC haute performance individuel.

## Frameworks de r√©f√©rence

S'inspirer des frameworks existants :
- Autogen
- CrewAI
- MemGPT
- AnythingLLM

## LLM adapt√©s aux besoins

### Assimilation rapide
- [Llama-3-8B-Instruct-Gradient-1048k](https://huggingface.co/spaces/Cyleux/Llama-3-8B-Instruct-Gradient-1048k) : Capable d'assimiler rapidement 1 million de tokens.
  - Nous l'avons install√© sur Lmstudio. Il n'est pas tr√®s intelligent ni instruit ...
    
### Production de code
- [Codestral](https://mistral.ai/news/codestral/) : 32k contexte, 81.1 sur HumanEval.

### Meilleurs LLM actuels
- Via API : [Claude 3.5 Sonnet](https://apidog.com/blog/claude-3-5-api/)
    - Abonnement pris
- En local : [MoA (Mixture of Anthropic Models)](https://github.com/togethercomputer/MoA)

### R√©cup√©ration de donn√©es sur le web
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) : Similaire √† Perplexity.
  - Installation faite sur Docker
## Techniques avanc√©es

### Fine-tuning
- [Guide de fine-tuning](https://www.perplexity.ai/search/How-to-finetune-sGJ9CD6zQ..8X.a9AsN_og)

### Function calling
- [Guide complet du function calling dans les LLM](https://thenewstack.io/a-comprehensive-guide-to-function-calling-in-llms/)


# Executive summary

L'objectif est de cr√©er un assistant apte √† am√©liorer la productivit√© d'une √©quipe travaillant sur un projet.

Pour am√©liorer la productivit√©, la premi√®re √©tape consiste √† v√©rifier si notre besoin n'est pas d√©j√† couvert par ailleurs et accessible sur le Web.
- Perplexity permet de faire ce type de recherche mais n'√©tant pas open source on ne peut automatiser sa mise en oeuvre et le traitement des donn√©es collect√©es.
- Perplexica est son √©quivalent open source que nous avons install√© en local. Le logiciel a √©t√© adapt√© pour permettre le traitement des donn√©es collect√©es.
- Nous allons dans un premier temps utiliser "sonnet 3.5" qui est le meilleur LLM actuel. Nous avons souscrit √† la version pro et √† l'utilisation via API de ce logiciel.
- Nous avons √©galement impl√©ment√© une variante de GPT-Research (fonctionnant avec sonnet3.5, Haiku et les embedding OpenAi). Cette variante permet de faire un rapport au format markdown √† partir d'une simple requ√™te **dans un script python**
- La suite concernera:
  - La mise en place d'un outil de codage performant (sonnet 3.5 avec agent, recherche web, it√©ration en cas d'erreur + explorer tout un repository Github.
  - L'√©valuation de RAGGraph (car l'augementation du contexte a ses limites)
  - Open Interpreter avec une vision locale (VisionLLM semble un bon candidat) 
 


# Logbook
Ceci est un logbook qui montre l'√©volution de ce projet au fil du temps

**26/06/2024**
- Notre premier objectif est de rapatrier des donn√©es issues du web pour rendre le LLM plus expert dans unn domaine donn√©.
- Cela est possible avec le logiciel perplexity (payant dans sa version pro) mais comme nous utiliserons son √©quivalent opensource [perplexica](https://github.com/ItzCrazyKns/Perplexica)
  Nous avons installer Perplexica en suivant les instructions avec les API d'openAI, de Groq ainsi que Ollama. Ollama doit √™tre install√© via Docker:
  
  `docker pull ollama/ollama:latest`
  `docker run -d -p 11434:11434 ollama/ollama:latest`

  Nous avons un probl√®me de connexion au serveur √† r√©soudre quand on lance perplexica.L'erreur provenait de l'absence de cr√©dit sur openai. J'utilse Groq llama70b moins cher et plus rapide √† mettre dans les param√®tres de Perplexica. L'IHM est analgue √† celui de Perplexity mais fonctionne en local, les requ√®tes web sont anonymis√©es.

  ![image](https://github.com/jpbrasile/Teambot/assets/8331027/bde4c7f5-dc9a-4c86-a3bc-9d475a334f74)

**Bibliographie:**

[llm r√©duit ultra-rapide](https://huggingface.co/PowerInfer/TurboSparse-Mixtral): Une nouvelle m√©thode de rar√©faction bas√©e sur dReLU qui augmente la parcimonie du mod√®le √† 90 % tout en maintenant les performances, atteignant une acc√©l√©ration de 2 √† 5 fois lors de l'inf√©rence.

[agents s'am√©liorant avec le temps](https://arxiv.org/abs/2404.11964)

[Les agents intelligents serverless permettent d'automatiser et de g√©rer facilement des applications cloud sans avoir √† s'occuper des serveurs](https://github.com/ruvnet/agileagents)

[üîß Maestro est un cadre pour orchestrer intelligemment les sous-agents utilisant Claude Opus et d'autres mod√®les AI.
üîÑ Il supporte plusieurs mod√®les AI comme Opus, Haiku, GPT-4o, LMStudio, et Ollama.
üì¶ Les scripts sont organis√©s en fichiers distincts pour chaque fonctionnalit√© AI.
üåê Int√©gration d'une application Flask pour une interface utilisateur conviviale.](https://github.com/Doriandarko/maestro)

[Avec Sonnet 3.5 code avec web search and file management](https://github.com/Doriandarko/claude-engineer)

[Mille pages de data en m√©moire court terme (contexte 1 million tokens)[https://huggingface.co/spaces/Cyleux/Llama-3-8B-Instruct-Gradient-1048k)

[ $0.03 per hour of transcription](https://console.groq.com/playground?model=whisper-large-v3)

[Open Web UI](https://github.com/open-webui/open-webui) offre une interface utilisateur conviviale et extensible pour g√©rer des mod√®les de langage (LLM) en local, compatible avec les API d'OpenAI et Ollama. Il propose des fonctionnalit√©s avanc√©es telles que la prise en charge des plugins Python, la communication vocale/vid√©o, et la g√©n√©ration d'images, tout en √©tant accessible sur divers appareils.

[**MOOC pour se former aux agents (Autogen)**](https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/)

[Base](https://learn.deeplearning.ai/courses/ai-agentic-design-patterns-with-autogen/lesson/2/multi-agent-conversation-and-stand-up-comedy)

**27/06/2024**
- Il nous faut pouvoir modifier le programme Perplexica disponible sur Github
- [continue](https://github.com/continuedev/continue) peut analyser et adapter le programme

**28/06/2024**
... malheureusement _continue_ ne poss√®de pas d'API. Nous avons trouv√© une alternative: 

**R√©sum√© du besoin :**

Vous souhaitez automatiser l'utilisation de la commande @codebase de l'assistant de codage Continue, afin d'analyser automatiquement un r√©f√©rentiel entier de code. Vous cherchez une solution pour int√©grer cette fonctionnalit√© dans un programme Python.

**Proposition de solution :**

Bien que l'automatisation directe de @codebase via un programme Python ne soit pas une fonctionnalit√© standard de Continue, voici une approche alternative que vous pourriez envisager :
- Utilisez un script Python pour consolider tout le contenu du r√©f√©rentiel dans un seul fichier texte, en pr√©servant la structure des chemins de fichiers.
- Employez un mod√®le de langage large (LLM) avec une grande fen√™tre de contexte, comme DeepSeek Coder V2, qui peut traiter de grandes quantit√©s de code.
- Cr√©ez une interface en Python pour interagir avec le LLM, lui permettant d'analyser le fichier consolid√© et de r√©pondre √† des questions sur le code.
- Int√©grez un agent de recherche web pour compl√©ter les informations manquantes si n√©cessaire.
  
Cette approche vous permettrait d'obtenir une fonctionnalit√© similaire √† @codebase, mais de mani√®re automatis√©e et int√©gr√©e √† votre programme Python. Cela vous donnerait la flexibilit√© d'analyser l'ensemble du r√©f√©rentiel et d'interagir avec le code de mani√®re programmatique.

[Sonnet 3.5 donne le code](https://claude.ai/chat/aa8d87af-aa47-41ad-b364-d082ba649184)

Le fichier g√©n√©r√© est trop important pour √™tre exploit√©  par sonnet 3.5 et ChatGPTo. Nous t√©l√©chargeons deepseekcoder (contexte de 100 k) 

**29/06/2024**
- Abonnement √† Antropic pro afin d'avoir un fonctionneemnt de sonnet 3.5 optimal (200 k de contexte).
- R√©pertoire TeambotV1 cr√©e avec Perplexica fonctionnel 
- Nous avons relanc√© une adaptation de perplexica pour r√©cup√©rer les donn√©es en local avec succ√®s gr√¢ce √† [sonnet 3.5](https://claude.ai/chat/5a6553cd-6040-459d-98c5-d37b1dc359a5).

**30/06/2024**
- Je me suis abonn√© √† l'API antropic et j'ai r√©alis√© mon premier chat "helloworld.py avec bien s√ªr sonnet 3.5 qui m'a donn√© le code correspondant !
- Nous pouvons maintenant r√©cup√©rer les donn√©es sur n'importe quel sujet via le net et stocker ces informations localement. La taille de ces donn√©es peut d√©passer le contexte, je vais donc r√©aliser un RAG avec l'aide de Sonnet.

- R√©cup√©ration de donn√©es sur n'importe quel sujet via le web
- Stockage local des informations r√©cup√©r√©es
- Utilisation de Sonnet pour cr√©er une base de donn√©es questions-r√©ponses
- Mise en place d'un syst√®me RAG (Retrieval Augmented Generation) avec cette base de donn√©es
- Recherche de corr√©lation entre la question pos√©e et les questions stock√©es
- Possibilit√© d'utiliser la base de donn√©es pour l'alignement d'un LLM open source

Les principaux avantages de cette approche sont :
- Meilleure corr√©lation entre les questions et les r√©ponses par rapport √† un RAG traditionnel
- Base de connaissances personnalis√©e et sp√©cifique au domaine d'int√©r√™t
- Potentiel d'am√©lioration de la pr√©cision et de la pertinence des r√©ponses
- Flexibilit√© pour mettre √† jour et enrichir continuellement la base de donn√©es

Cependant, il faudra relever certains d√©fis :
- Complexit√© technique dans la mise en ≈ìuvre du syst√®me Sonnet
- Assurance de la qualit√© des paires questions-r√©ponses g√©n√©r√©es
- Gestion efficace de la base de donn√©es √† mesure qu'elle s'agrandit
- Mise en place d'un syst√®me d'√©valuation robuste pour mesurer l'efficacit√©

Cette approche innovante combine plusieurs technologies avanc√©es (RAG, Sonnet, alignement de LLM) pour potentiellement cr√©er un syst√®me plus performant et personnalis√©.

**01/07/2024**
- **Web scraping :**
  - [00:00](https://www.youtube.com/watch?v=KAvuVUh0XU8&t=0s) üåê Crawl4AI is an open-source, LM-friendly web crawler and scraper that supports multiple URLs, extracts media tags, and returns structured data in JSON format.
  - [01:06](https://www.youtube.com/watch?v=KAvuVUh0XU8&t=66s) üì¶ Using Crawl4AI simplifies web scraping by automating the process of defining elements, parsing data, and converting it into structured formats, integrated with AI agents.
  - [02:56](https://www.youtube.com/watch?v=KAvuVUh0XU8&t=176s) üõ†Ô∏è You can initiate a basic crawl and extract data from a URL using just a few lines of Python code with Coll 4 AI, demonstrating its ease of use and efficiency.
  - [04:48](https://www.youtube.com/watch?v=KAvuVUh0XU8&t=288s) üìä Crawl4AI facilitates structured data extraction using LLM, allowing extraction of specific information like model names and pricing details from web pages.
  - [06:37](https://www.youtube.com/watch?v=KAvuVUh0XU8&t=397s) ü§ñ Integrating Crawl4AI with AI agents such as web scraper, data cleaner, and data analyzer agents automates data extraction, cleaning, and analysis processes, generating detailed reports.
 
- **[Function calling LLM Benchmark](https://gorilla.cs.berkeley.edu/leaderboard.html)** : Gorilla est un tr√®s bon compromis open source et Sonnet 3.5 le meilleur √† ce jour
- **Conversion de fichier au format Markdown :**
  -  [00:00](https://youtu.be/8446xEEq8RI?t=0s) üõ†Ô∏è Introduction √† AutoMD

  - Pr√©sentation d'AutoMD, un outil Python pour convertir des fichiers en documents Markdown pr√™ts pour LLM.
  - AutoMD est gratuit et fonctionne localement.

  - [01:23](https://youtu.be/8446xEEq8RI?t=83s) üìÇ Fonctionnalit√©s d'AutoMD
  
    - Supporte plusieurs types de fichiers et dossiers zip.
    - G√©n√®re des fichiers Markdown individuels ou multiples avec m√©tadonn√©es et table des mati√®res.
  
  - [02:16](https://youtu.be/8446xEEq8RI?t=136s) üìù Formats de fichiers pris en charge
  
    - Supporte de nombreuses extensions de fichiers comme JSON, CSS, etc.
    - Mise √† jour r√©guli√®re des extensions support√©es.
  
  - [03:25](https://youtu.be/8446xEEq8RI?t=205s) ‚öôÔ∏è Installation d'AutoMD
  
    - Instructions pour installer AutoMD et cr√©er un environnement Python.
    - Exemple de clonage et ouverture de projet dans VS Code.
  
  - [06:17](https://youtu.be/8446xEEq8RI?t=377s) üìÅ Utilisation de l'interface utilisateur
  
    - T√©l√©chargement de fichiers et s√©lection des options de sortie.
    - Processus de g√©n√©ration des fichiers Markdown avec table des mati√®res et m√©tadonn√©es.
  
  - [08:02](https://youtu.be/8446xEEq8RI?t=482s) üîç Conclusion et d√©monstration finale
  
    - Visualisation des fichiers g√©n√©r√©s avec les diff√©rentes m√©tadonn√©es et contenu format√©.
    - Encouragement √† tester l'outil et partage des retours.
   
  - **coding engineer**:
    - [00:00](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=0s) üñ•Ô∏è Introduction to Claude Engineer
      - Overview of Claude Engineer capabilities,
      - Describes how it assists in coding tasks, 
      - Example of creating a YouTube video downloader script.
    - [02:06](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=126s) üõ°Ô∏è Importance of Safety and Confirmation
      - Emphasis on the need for user confirmation in coding,
      - Discussion on safety measures to prevent unintended actions,
      - Mention of potential issues with agents and illegal activities.
    - [03:56](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=236s) üéØ Enhancements and Future Projects
      - Demonstrates the flexibility of modifying scripts,
      - Transition to working on new projects like HTML and CSS,
      - Highlights of ongoing trends in AI tools and automation.
    - [05:06](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=306s) üéÆ Snake Game Implementation
      - Creation of a Snake game using Claude Engineer,
      - Explanation of the steps involved in setting up and running the game,
      - Insights into the capabilities of the tool in building functional applications.
    - [07:22](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=442s) üåâ Advancements in AI Models
      - Discussion on the rapid progress of AI models,
      - Theory on how Anthropic improves model intelligence,
      - Reference to the Golden Gate Cloud experiment.
    - [10:08](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=608s) üèÉ‚Äç‚ôÇÔ∏è Competitive Progress of AI Companies
      - Comparison of Anthropic and OpenAI approaches,
      - Speculation on the future of AI model capabilities,
      - Reflection on the balance between user experience and model improvement.
    - [12:10](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=730s) üöÄ Exponential Improvement in AI Utility
      - Concept of users becoming more efficient with better AI tools,
      - Analogy of AI tools enhancing user capabilities like driving a better car,
      - Importance of adapting to and leveraging advanced AI technologies.
    - [14:56](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=896s) üîß Building and Using Advanced AI Tools
      - Example of winning a developer challenge with AI assistance,
      - Preview of upcoming live app projects,
      - Insights into the practical applications and future potential of AI tools.
    - [18:06](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1086s) üìë Workflow and Development with Claude Engineer
      - Explanation of the workflow used to build Claude Engineer,
      - Demonstration of using Claude for function calls and documentation,
      - Step-by-step guide on starting a new project with Claude.
    - [20:31](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1231s) üìö Importance of Training Data
      - Emphasizing the necessity of knowing what's in the training data,
      - Using documentation to ensure model accuracy.
    - [21:13](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1273s) üîÑ Best Practices for Function Calls
      - Describing function calling procedures,
      - Importance of running tools twice for verification.
    - [23:00](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1380s) üß™ Testing and Experimentation
      - Creating and testing scripts quickly,
      - Demonstrating function calling with weather data.
    - [24:11](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1451s) üöÄ Encouraging Experimentation
      - Motivating viewers to start building projects,
      - Highlighting the ease of using AI tools for programming.
    - [24:38](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1478s) ‚ùì Community Engagement
      - Answering community questions,
      - Promoting community involvement in AI development.
    - [25:07](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1507s) üí° Surprising Use Cases and Future Plans
      - Discussing unexpected use cases of Cloud Engineer,
      - Future functionalities and improvements.
    - [26:00](https://www.youtube.com/watch?v=tq9yN-j5o3M&t=1560s) üíº Advice for AI Entrepreneurs
      - Encouraging solo entrepreneurs to build what resonates with them,
      - Importance of creating consumer-friendly AI tools.
     

     
    - [**G√©n√©rateur de voix text to speech 2024**](https://www.youtube.com/watch?v=u5QnjiCRRmU):
      - üéôÔ∏è Text to Speech Open AI est un outil de synth√®se vocale gratuit de haute qualit√©.
      - üí∏ Ce logiciel co√ªte seulement 6 $ pour une version payante, moins cher que d'autres outils similaires.
      - üì± Il est accessible sur mobile et propose des voix r√©alistes avec des options d'√©motion.
      - üåê L'interface est facile √† utiliser : il suffit de chercher "text to speech open AI" sur Google.
      - üéß Chaque cha√Æne YouTube peut choisir une voix adapt√©e √† son contenu, comme une voix motivante ou amusante.
      - üñãÔ∏è Vous pouvez copier votre script, choisir la vitesse et la qualit√© audio, et g√©n√©rer jusqu'√† 3000 mots gratuitement.
      - üé∂ Le logiciel Audacity peut √™tre utilis√© pour am√©liorer la qualit√© sonore de la voix g√©n√©r√©e.
      - üó£Ô∏è L'outil permet √©galement de cr√©er des dialogues engageants entre plusieurs personnages.
    - [**Agent codeur**:](https://github.com/huangd1999/AgentCoder)
      - ü§ñ Trois agents : AgentCoder utilise un agent programmeur, un agent concepteur de tests et un agent ex√©cuteur de tests pour g√©n√©rer et tester du code.
      - üåü Performance sup√©rieure : AgentCoder surpasse les mod√®les de LLM existants dans divers sc√©narios de codage.
      - üìà Am√©lioration des r√©sultats : AgentCoder augmente le pass@1 √† 77.4% et 89.1% sur les ensembles de donn√©es HumanEval-ET et MBPP-ET.
      - üîÑ Format de sortie : Les agents suivent un format de sortie sp√©cifique pour une analyse pr√©cise par l'agent ex√©cuteur.
    - [**Cr√©ation automatique d'agents**](https://github.com/jgravelle/AutoGroq)
      - ü§ñ Introduction d'AutoGroq‚Ñ¢ et son r√¥le dans la cr√©ation d'agents IA.
      - üñ•Ô∏è Les agents IA sont des programmes informatiques autonomes.
      - üöÄ AutoGroq‚Ñ¢ facilite la cr√©ation d'agents IA pour les utilisateurs.
      - üîÑ M√©thode standard vs. AutoGroq‚Ñ¢ : r√©soudre d'abord le probl√®me, puis cr√©er l'agent sp√©cialis√©.
      - üß© Agents personnalisables : modification, ajout de comp√©tences, apprentissage.
      - üåê Collaboration automatique des agents gr√¢ce √† AutoGroq‚Ñ¢ et autogen.
      - üèóÔ∏è AutoGroq‚Ñ¢ comme plateforme de construction et de test.
      - üåç Applications r√©elles et environnement de d√©ploiement via autogen.
    - [**Monitoring des agents**](https://github.com/AgentOps-AI/agentops):
      - üñ•Ô∏è Pr√©sentation des d√©fis des agents IA : co√ªt, latence et observabilit√©.
      - üìä Importance de la surveillance, des tests et des analyses pour les agents IA.
      - üõ†Ô∏è Configuration initiale et gestion des cl√©s API pour AgentOps.
      - üß© Int√©gration de Crew AI avec AgentOps pour la surveillance des agents.
      - üìù D√©veloppement du code pour initialiser et surveiller les agents IA.
      - üîÑ D√©finition des r√¥les et des t√¢ches pour les agents Crew AI.
      - üöÄ Lancement et r√©sultats de l'ex√©cution des agents avec AgentOps.
      - üì¢ Conclusion, encouragement √† s'abonner et rejoindre la communaut√© Discord.    - [**Monitoring des agents**](https://github.com/AgentOps-AI/agentops):
      - üñ•Ô∏è Pr√©sentation des d√©fis des agents IA : co√ªt, latence et observabilit√©.
      - üìä Importance de la surveillance, des tests et des analyses pour les agents IA.
      - üõ†Ô∏è Configuration initiale et gestion des cl√©s API pour AgentOps.
      - üß© Int√©gration de Crew AI avec AgentOps pour la surveillance des agents.
      - üìù D√©veloppement du code pour initialiser et surveiller les agents IA.
      - üîÑ D√©finition des r√¥les et des t√¢ches pour les agents Crew AI.
      - üöÄ Lancement et r√©sultats de l'ex√©cution des agents avec AgentOps.
      - üì¢ Conclusion, encouragement √† s'abonner et rejoindre la communaut√© Discord.
    - [**Autogen update**](https://www.youtube.com/watch?v=ymz4RIUIask)
      - [00:00] üß† Microsoft AutoGen a re√ßu une mise √† jour majeure pour les t√¢ches complexes et l'am√©lioration des performances des agents.
      - [00:11] üîß AutoGen est un cadre de conversation multi-agent open source pour les applications de mod√®les de langage.
      - [00:40] üöÄ La mise √† jour permet la collaboration entre agents pour accomplir des t√¢ches multi-√©tapes plus efficacement que les solutions √† agent unique.
      - [02:20] üí° Adam Fourney de Microsoft a pr√©sent√© cette am√©lioration en montrant comment les agents peuvent surpasser les solutions pr√©c√©dentes sur des benchmarks.
      - [02:59] üë• Les agents peuvent se sp√©cialiser et utiliser divers outils, permettant une meilleure g√©n√©ration pour des t√¢ches complexes.
      - [05:00] üîç Exemple : r√©soudre des t√¢ches complexes en utilisant une base de donn√©es, illustr√© par une recherche sur les crocodiles non indig√®nes en Floride.
      - [07:04] üåê AutoGen est open source et disponible sur GitHub.
      - [09:26] üìà Les futurs d√©veloppements incluent des agents capables d'apprendre et de s'am√©liorer, avec une meilleure compr√©hension des images et des captures d'√©cran.
     
      **02/07/2024**
  - Extraction des donn√©es de Perplexica avec:
      
  `(teambot) PS C:\Users\test\Documents\TeambotV1\temp_repo> python .\url-extractor-debug.py`. La requ√®te √† Perplexica est faite via `http://localhost:3000/`

  -[**GPT Researcher**](https://docs.gptr.dev/docs/gpt-researcher/introduction) est un √©quivalent √† Perplexica

    - L'adaptation de ce logiciel pour utiliser les LLM Antropic (sonnet 3.5 et Haiku) a √©t√© faite.
    - Il faut conserver l'abonneement √† openai pour la cr√©ation de l'embedding 
    - Lancement avec `(teambot) PS C:\Users\test\Documents\TeambotV1\gpt-researcher> uvicorn main:app --reload`
    - Aller sur `http://localhost:8000/#form`pour le lancer

    - **Modifications effectu√©es pour pouvoir utiliser GPT-Resercher avec un script Python:**

[Le fil de la discussion avec sonnet 3.5](https://claude.ai/chat/49d8dd3c-e666-4851-ba3e-835da8377163)

      1. Transition vers Anthropic :
         - Remplacement des appels √† l'API OpenAI par des appels √† l'API Anthropic.
         - Mise √† jour des variables d'environnement pour utiliser la cl√© API Anthropic.
         - Adaptation du code pour utiliser le format de requ√™te sp√©cifique √† Anthropic.
      
      2. Ajout de capacit√©s API :
         - Cr√©ation d'un nouvel endpoint API dans `server.py` pour permettre les requ√™tes de recherche via HTTP.
         - Modification de `WebSocketManager` pour fonctionner avec et sans connexion WebSocket.
         - Adaptation des classes `BasicReport` et `DetailedReport` pour g√©rer les cas sans WebSocket.
      
      3. Mise √† jour de la g√©n√©ration de rapports :
         - Remplacement de la biblioth√®que de conversion PDF probl√©matique par ReportLab pour une meilleure compatibilit√©.
         - Simplification du processus de g√©n√©ration de PDF pour √©viter les d√©pendances syst√®me complexes.
      
      Guide de d√©marrage rapide :
      
      1. Configuration :
         - Clonez le repository GPT-Researcher.
         - Cr√©ez un fichier `.env` √† la racine du projet avec votre cl√© API Anthropic :
           ```
           ANTHROPIC_API_KEY=votre_cl√©_api_ici
           ```
      
      2. Installation :
         - Installez les d√©pendances : `pip install -r requirements.txt`
         - Installez ReportLab : `pip install reportlab`
      
      3. Lancement du serveur :
         - Ex√©cutez : `python main.py`
         - Le serveur d√©marrera sur `http://localhost:8000`
      
      4. Utilisation de l'API (voir l'exemple test_api.py):
         - Envoyez une requ√™te POST √† `http://localhost:8000/api/research` avec un corps JSON :
           ```json
           {
             "task": "Votre question de recherche ici",
             "report_type": "research_report",
             "agent": "RecommendedAgent"
           }
           ```
         - La r√©ponse inclura le rapport et les chemins des fichiers g√©n√©r√©s (PDF, DOCX, MD).
      
      5. Utilisation de l'interface Web :
         - Ouvrez un navigateur et acc√©dez √† `http://localhost:8000`
         - Utilisez l'interface pour saisir votre question et obtenir des r√©sultats en temps r√©el.
      
      6. D√©pannage :
         - V√©rifiez les logs du serveur pour les erreurs √©ventuelles.
         - Assurez-vous que votre cl√© API Anthropic est valide et correctement configur√©e.
      
      Ce guide devrait vous permettre de d√©marrer rapidement avec la version modifi√©e de GPT-Researcher utilisant Anthropic et offrant des capacit√©s d'API.

  **3/07/2024**
- Pour coder en open source : CodeQwen1.5 ![image](https://github.com/jpbrasile/Teambot/assets/8331027/d321df22-7bc7-40e8-8ebb-4f8129c1a0a4)
- [ScrapeGraphAI](https://github.com/VinciGit00/Scrapegraph-ai?tab=readme-ov-file).
      ### üíª Utilisation
      Plusieurs pipelines de scraping standard peuvent √™tre utilis√©s pour extraire des informations d'un site web (ou d'un fichier local) :
      
      - **SmartScraperGraph** : Scraper de page unique qui n√©cessite seulement une invite utilisateur et une source d'entr√©e.
      - **SearchGraph** : Scraper multi-pages qui extrait des informations des n premiers r√©sultats de recherche d'un moteur de recherche.
      - **SpeechGraph** : Scraper de page unique qui extrait des informations d'un site web et g√©n√®re un fichier audio.
      - **ScriptCreatorGraph** : Scraper de page unique qui extrait des informations d'un site web et g√©n√®re un script Python.
      - **SmartScraperMultiGraph** : Scraper multi-pages qui extrait des informations de plusieurs pages √† partir d'une seule invite et d'une liste de sources.
      - **ScriptCreatorMultiGraph** : Scraper multi-pages qui g√©n√®re un script Python pour extraire des informations de plusieurs pages √† partir d'une seule invite et d'une liste de sources.
      
      Il est possible d'utiliser diff√©rents mod√®les de langage (LLM) via des API, telles que OpenAI, Groq, Azure et Gemini, ou des mod√®les locaux utilisant Ollama.
      
      - Une √©valuation de ScrapeGraphAI est disponible en ligne [ici](https://scrapegraph-ai-web-dashboard.streamlit.app/)
- [**The pi.pe**](https://github.com/emcf/thepipe)
  - Extrait du contenu en markdown et des visuels √† partir des URLs de PDFs, documents, pr√©sentations, vid√©os, et plus encore, pr√™t pour les mod√®les de langage multimodaux (LLMs).
  - Utile pour une r√©cup√©ration multimodale de document comme Arxiv avec l'exploitation des figures et des tables.

- [**Quel LLM pour "voir" une vid√©o**](https://video-mme.github.io/home_page.html#leaderboard)
  - [![image](https://github.com/jpbrasile/Teambot/assets/8331027/20a48fdd-9e4d-41dc-a769-925a145df504)](https://encord.com/blog/gpt-4-vision-alternatives/#:~:text=Alternatives%20to%20GPT%2D4%20Vision,-Open%20source%20alternatives&text=four%20popular%20alternatives%3A-,LLaVa%201.5,BakLLaVa)
  - [https://github.com/OpenGVLab/InternVL](https://internvl.opengvlab.com/) est un bon candidat. Test en ligne possible via l'hyperlien. Voir aussi [ici](https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5)
  - Sonnet 3.5 reste un bon compromis performance/prix mais ne permet pas d'extraire la bounding box
  ![image](https://github.com/jpbrasile/Teambot/assets/8331027/7298d0ab-5281-48a1-b3e3-0b053d5bd245)

- Taskgen
    ### R√©sum√© du projet TaskGen
    
    **TaskGen** est un cadre agentique bas√© sur les t√¢ches, utilisant StrictJSON comme noyau. Ce projet open-source vise √† fournir une m√©thode efficace pour ex√©cuter des t√¢ches en utilisant des agents aliment√©s par des mod√®les de langage (LLM). Voici les principales capacit√©s et forces de TaskGen :
    
    #### Fonctionnalit√©s Cl√©s
    
    - **Division des T√¢ches** : Les t√¢ches sont divis√©es en sous-t√¢ches pour des solutions plus cibl√©es.
    - **Agent Unique** : Fonctionne avec des fonctions LLM et des fonctions externes.
    - **M√©taAgent** : Utilise des agents internes comme fonctions pour des t√¢ches complexes.
    - **Variables Partag√©es** : Support multi-modalit√© pour un contexte global et des variables persistantes.
    - **G√©n√©ration Augment√©e par R√©cup√©ration (RAG)** : Utilise la r√©cup√©ration sur l'espace des fonctions pour une g√©n√©ration de contenu am√©lior√©e.
    - **M√©moire** : Fournit des invites suppl√©mentaires bas√©es sur les t√¢ches pr√©c√©dentes pour am√©liorer la coh√©rence des t√¢ches.
    - **Mode Asynchrone** : Support pour l'agent asynchrone, les fonctions et strict_json.
    
    #### Avantages de la Messagerie JSON
    
    - **Format JSON** : Aide √† la g√©n√©ration de la cha√Æne de pens√©e naturellement et est moins verbeux que le texte libre.
    - **Analyse Naturelle** : Permet une analyse naturelle de multiples champs de sortie par les agents.
    - **StrictJSON** : Assure que tous les champs de sortie sont pr√©sents et au bon format pour le traitement en aval.
    
    #### Utilisation et Exemples
    
    - **Installation** : `pip install taskgen-ai`
    - **Configuration** : Configuration de la cl√© API OpenAI et importation des fonctions n√©cessaires.
    - **Cr√©ation d'Agent** : Cr√©ez un agent et ex√©cutez des t√¢ches en divisant les t√¢ches assign√©es en sous-t√¢ches.
    - **R√©ponse de l'Agent** : Les agents fournissent des r√©ponses bas√©es sur les r√©sultats des sous-t√¢ches ex√©cut√©es.
    
    #### Avantages par rapport √† AutoGen
    
    - **Efficacit√©** : TaskGen est moins verbeux et plus cibl√© que les cadres agentiques bas√©s sur la conversation comme AutoGen.
    - **Flexibilit√©** : Permet l'utilisation de fonctions externes et d'agents internes pour une grande vari√©t√© de t√¢ches.
    - **M√©moire et Contexte Global** : Utilise des variables partag√©es et une m√©moire pour am√©liorer la coh√©rence et la performance des agents.
  
    Pour plus d'informations, visitez le [d√©p√¥t GitHub de TaskGen](https://github.com/simbianai/taskgen).

**4/7/2024**
- [VisionLLM](https://github.com/OpenGVLab/VisionLLM): permet d'√©ffectuer une centaine de t√¢ches distinctes √† partir d'une image et d'un prompt.
- [**Fabric**](https://github.com/danielmiessler/fabric?tab=readme-ov-file) :Fabric est un framework open-source destin√© √† augmenter les capacit√©s humaines gr√¢ce √† l'IA. Voici ses principales fonctionnalit√©s :

1. **Collection et int√©gration de prompts** : Appel√©s Patterns, pour diverses activit√©s personnelles et professionnelles.
2. **Modularit√©** : Inclut des composants comme le Mill (serveur optionnel), les Patterns (prompts sp√©cifiques) et les Stitches (encha√Ænements de Patterns).
3. **Compatibilit√©** : Fonctionne avec divers mod√®les d'IA, y compris OpenAI et autres serveurs compatibles.
4. **Utilisation de Markdown** : Assure une lisibilit√© et une modifiabilit√© maximales des Patterns.
5. **Agents d'IA** : Int√®gre PraisonAI pour automatiser des t√¢ches complexes.
6. **Outils auxiliaires** : Pour extraire des transcriptions YouTube, transcrire des fichiers audio, etc.

Fabric facilite l'int√©gration de l'IA dans la vie quotidienne en rendant les prompts accessibles et utilisables.


- ü§ñ Assistant IA aliment√© par Claude 3.5 d'Anthropic pour des interactions en langage naturel
- üßë‚Äçüíª Ex√©cution de code Python s√©curis√©e dans un environnement Jupyter Notebook
- ‚öõÔ∏è Cr√©ation et rendu dynamiques de composants React en temps r√©el
- üìÅ Gestion int√©gr√©e des op√©rations de fichiers, incluant les t√©l√©versements et t√©l√©chargements
- üìä Visualisation avanc√©e des donn√©es avec des biblioth√®ques comme matplotlib
- üõ†Ô∏è Utilisation adaptative des outils, alternant entre Python, React et les op√©rations de fichiers
- üåê Acc√®s aux ressources web et possibilit√© de faire des requ√™tes API
- üîß Interface intuitive et conviviale via Streamlit
- üêõ Gestion robuste des erreurs avec des messages clairs et explicatifs
- üñ•Ô∏è Gestion flexible des paquets Python avec possibilit√© d'installation suppl√©mentaire
- üîÑ Diagramme de workflow en temps r√©el bas√© sur LangGraph

**ü§ñ Claude Engineer**
Claude Engineer est une interface en ligne de commande (CLI) interactive qui exploite la puissance du mod√®le Claude-3.5-Sonnet d'Anthropic pour aider aux t√¢ches de d√©veloppement logiciel. Cet outil combine les capacit√©s d'un grand mod√®le de langage avec des op√©rations pratiques sur le syst√®me de fichiers et des fonctionnalit√©s de recherche sur le web.

‚ú® Fonctionnalit√©s
üí¨ Interface de chat interactive avec Claude-3.5-Sonnet
üìÅ Op√©rations sur le syst√®me de fichiers (cr√©ation de dossiers, fichiers, lecture/√©criture de fichiers)
üîç Capacit√©s de recherche sur le web utilisant l'API Tavily
üåà Surlignage de la syntaxe pour les extraits de code
üèóÔ∏è Cr√©ation et gestion de la structure de projet
üßê Analyse de code et suggestions d'am√©lioration
üñºÔ∏è Prise en charge des capacit√©s de vision via le glisser-d√©poser d'images dans le terminal
üöÄ Mode automatique pour l'ex√©cution autonome des t√¢ches
üîÑ Suivi des it√©rations en mode automatique
üìä √âdition de fichiers bas√©e sur les diff√©rences pour des modifications de code pr√©cises

[**Open Interpreter**](openinterpreter.com)
- üåê Open Interpreter fournit une interface en langage naturel pour les ordinateurs.
- üìà Permet d'ex√©cuter du code (Python, Javascript, Shell, etc.) localement via une interface de type ChatGPT.
- üñ•Ô∏è Peut cr√©er et modifier des photos, vid√©os, PDF, et plus encore.
- üåç Acc√®s complet √† Internet sans restriction de taille de fichier ou de temps d'ex√©cution.
- üîê Ex√©cution s√©curis√©e avec demande de confirmation avant d'ex√©cuter du code.
- üõ†Ô∏è Installation et utilisation facile via la ligne de commande ou Python.
- ü§ù Contribution de la communaut√© encourag√©e avec des directives de contribution claires.
- üìã Documentation compl√®te disponible en ligne et hors ligne.
- üöÄ Mode local avec support pour divers serveurs compatibles OpenAI.
- üîÑ Historique des conversations sauvegard√© et restaur√© pour une continuit√© des t√¢ches.
- üíª Interface en langage naturel pour les ordinateurs, rendant la programmation accessible √† tous.
- üêç Majoritairement cod√© en Python (98.7%).
- üîí Distribu√© sous licence AGPL-3.0, garantissant une s√©curit√© √©lev√©e.
- üìà Permet de nouvelles m√©thodes de travail rapides et efficaces, avec des workflows simplifi√©s.
- üåê Site web officiel : openinterpreter.com.
- üìä Statistiques et informations d√©taill√©es sur GitHub.
- üöÄ Introduction de Local III : Libert√© personnelle et acc√®s priv√© √† l'intelligence machine.
- üñ•Ô∏è Explorateur local : Installation interactive pour s√©lectionner et t√©l√©charger des mod√®les.
- üí¨ Mod√®le i : Point d'acc√®s gratuit servant Llama3-70B, contribuant √† l'entra√Ænement d'un mod√®le open-source.
- ü§ñ Int√©gration profonde avec Ollama : Commande unifi√©e pour acc√©der aux mod√®les Ollama.
- ‚öôÔ∏è Profils optimis√©s : Param√®tres recommand√©s pour les mod√®les Codestral, Llama3 et Qwen.
- üì∑ Vision locale : Rendu d'images avec le mod√®le de vision Moondream et extraction OCR.
- üñ±Ô∏è Mode OS local : Contr√¥le de la souris et du clavier, et interaction avec l'√©cran via le mod√®le Point.
- üí° Pourquoi Local ? : Promouvoir un acc√®s priv√© et local aux agents d'IA puissants.
.
[**OpenDevin**](https://github.com/OpenDevin/OpenDevin)
- ü§ñ Agent IA autonome pour le d√©veloppement logiciel
- üß† Utilise des mod√®les de langage avanc√©s comme GPT-4 par d√©faut
- üõ†Ô∏è Capable d'ex√©cuter des t√¢ches de programmation complexes
- üë• Collabore activement avec les d√©veloppeurs humains sur des projets
- üìù G√©n√®re du code de mani√®re autonome
- üêõ D√©tecte et corrige les bugs dans le code
- ‚ö° Optimise les programmes existants
- üîì Projet open source et gratuit
- üîß Configurable pour utiliser diff√©rents mod√®les de langage
- üñ•Ô∏è Interface utilisateur avec serveurs backend et frontend
- üìä Performances sup√©rieures aux agents IA pr√©c√©dents sur des benchmarks de codage
- üî¨ Cadre d'√©valuation simplifi√© pour tester les agents de codage
- üå± En d√©veloppement continu avec des am√©liorations r√©guli√®res



    
      
   

