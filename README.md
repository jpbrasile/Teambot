# Teambot

Nous allons entre**prendre** un voyage qui vous permettra de vous √©**prendre** de l'Intelligence artificielle car nous allons cr√©er votre nouvel ami intelligent et cultiv√©, toujours disponible et bienveillant √†  votre √©gard. 
- Il va commencer par **prendre** toute sortes de donn√©es (texte, image, son, vid√©o...)
- Il va devoir les com**prendre** afin d'utiliser ce savoir pour vous ap**prendre** tout ce que vous souhaitez.   
- Pour nos enseignants, il leur faudra d√©sap**prendre** leurs m√©thodes traditionnelles comme l'apprentissage des langues ou de la programmation pour s'adapter √† ce nouvel outil. 
- Mais il ne faut pas vous m√©**prendre**, √† charge √† vous de re**prendre** le contr√¥le des op√©rations et nul doute que les r√©sultats ne manqueront pas de vous sur**prendre** !!! 

# Teambot : Cahier des charges

## Introduction

Le travail d'√©quipe peut largement √™tre am√©lior√© avec l'aide des derni√®res technologies informatiques :

- Les ¬´ Large Language Models ¬ª (LLM) ont des capacit√©s qui s'am√©liorent de jour en jour.
- Les GPU permettent des ex√©cutions ultra-rapides de t√¢ches complexes telles que les mod√©lisations 3D.

Cependant, il n'existe pas actuellement d'environnement permettant un travail collaboratif efficace et simple d'emploi. **Teambot** vise √† combler ce manque.

Ce document √©tablit le cahier des charges de Teambot et identifie les frameworks les plus pertinents pour sa mise en ≈ìuvre.

## Fonctionnalit√©s principales

### 1. Workspace de travail

- Un espace d√©di√© par projet, ouvert √† l'√©quipe charg√©e de sa mise en ≈ìuvre.
- Supervision des √©changes pour correspondre aux valeurs et objectifs de l'entreprise.

### 2. Conservation intelligente du projet

- Stockage des donn√©es brutes du projet.
- Possibilit√© d'interroger le projet en langage naturel pour obtenir des r√©ponses ad√©quates.

### 3. LLM local et open source

- Contr√¥le complet du fonctionnement.
- Conservation de la confidentialit√© lorsque n√©cessaire.
- Utilisation d'un prompt syst√®me.

### 4. M√©moire √† court terme importante

- Permet des √©changes entre les divers acteurs sans perte de connaissance.

### 5. Bot d√©di√© √† chaque membre de l'√©quipe

Chaque bot personnel dispose de :

- Un espace personnel accessible uniquement par l'utilisateur (stockage des donn√©es sur son PC).
  - Sert d'assistant personnel et d'outil de formation continue.
- Acc√®s aux donn√©es du projet pertinentes pour l'utilisateur.
- Acc√®s √† des outils sp√©cifiques pour faciliter les t√¢ches.
- Interface via l'√©crit ou la parole.

#### Capacit√©s du bot

Le bot doit pouvoir :

- **Prendre** des donn√©es :
  - Fichiers locaux
  - Speech-to-text
  - Image/vid√©o to text (en particulier vid√©os youtube)
  - Via internet (en particulier assimilation des codes disponibles sur Github)
    
- **Assimiler** les donn√©es :
  - Dans sa m√©moire √† court terme (contexte)
  - Dans sa m√©moire √† long terme (RAG)
  - Dans ses "g√®nes" (fine-tuning)
    
- **Activer** des ressources sp√©cifiques (function calling)
  
- **Cr√©er et utiliser des outils** soit disponible sur API (gorilla) soit qu'il cr√©e lui m√™me en les programmant
  
- **Cr√©er des agents** susceptible de devenir expert dans un domaine donn√© gr√¢ce √† sa capacit√© d'apprentissage et √† la ma√Ætrise d'outils appropri√©s 

## Principes fondamentaux

- Le bot est un outil permettant un travail plus efficace, mais **pilot√© par l'homme qui en assure le contr√¥le et la pertinence**.
- Objectif : √©viter au mieux les hallucinations.

## Ressources mat√©rielles

- Implantation locale de Teambot sur un serveur.
- Accessible √† tout membre de l'√©quipe disposant des droits n√©cessaires, sans besoin de PC haute performance individuel.

## Frameworks de r√©f√©rence

S'inspirer des frameworks existants :
- Autogen
- CrewAI
- MemGPT
- AnythingLLM

## LLM adapt√©s aux besoins

### Assimilation rapide
- [Llama-3-8B-Instruct-Gradient-1048k](https://huggingface.co/spaces/Cyleux/Llama-3-8B-Instruct-Gradient-1048k) : Capable d'assimiler rapidement 1 million de tokens.
  - Nous l'avons install√© sur Lmstudio. Il n'est pas tr√®s intelligent ni instruit ...
    
### Production de code
- [Codestral](https://mistral.ai/news/codestral/) : 32k contexte, 81.1 sur HumanEval.

### Meilleurs LLM actuels
- Via API : [Claude 3.5 Sonnet](https://apidog.com/blog/claude-3-5-api/)
    - Abonnement pris
- En local : [MoA (Mixture of Anthropic Models)](https://github.com/togethercomputer/MoA)

### R√©cup√©ration de donn√©es sur le web
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) : Similaire √† Perplexity.
  - Installation faie sur docker
## Techniques avanc√©es

### Fine-tuning
- [Guide de fine-tuning](https://www.perplexity.ai/search/How-to-finetune-sGJ9CD6zQ..8X.a9AsN_og)

### Function calling
- [Guide complet du function calling dans les LLM](https://thenewstack.io/a-comprehensive-guide-to-function-calling-in-llms/)


# Executive summary

L'objectif est de cr√©er un assistant apte √† am√©liorer la productivit√© d'une √©quipe travaillant sur un projet.

Pour am√©liorer la productivit√©, la premi√®re √©tape consiste √† v√©rifier si notre besoin n'est pas d√©j√† couvert par ailleurs et accessible sur le Web.
- Perplexity permet de faire ce type de recherche mais n'√©tant pas open source on ne peut automatiser sa mise en oeuvre et le traitement des donn√©es collect√©es.
- Perplexica est son √©quivalent open source que nous avons install√© en local. Le logiciel a √©t√© adapt√© pour permettre le traitement des donn√©es collect√©es.
- Nous allons dans un premier temps utiliser "sonnet 3.5" qui est le meilleur LLM actuel. Nous avons souscrit √† la version pro et √† l'utilisation via API de ce logiciel.
 


# Logbook
Ceci est un logbook qui montre l'√©volution de ce projet au fil du temps
**26/06/2024**
- Notre premier objectif est de rapatrier des donn√©es issues du web pour rendre le LLM plus expert dans unn domaine donn√©.
- Cela est possible avec le logiciel perplexity (payant dans sa version pro) mais comme nous utiliserons son √©quivalent opensource [perplexica](https://github.com/ItzCrazyKns/Perplexica)
  Nous avons installer Perplexica en suivant les instructions avec les API d'openAI, de Groq ainsi que Ollama. Ollama doit √™tre install√© via Docker:
  
  `docker pull ollama/ollama:latest`
  `docker run -d -p 11434:11434 ollama/ollama:latest`

  Nous avons un probl√®me de connexion au serveur √† r√©soudre quand on lance perplexica.L'erreur provenait de l'absence de cr√©dit sur openai. J'utilse Groq llama70b moins cher et plus rapide √† mettre dans les param√®tres de Perplexica. L'IHM est analgue √† celui de Perplexity mais fonctionne en local, les requ√®tes web sont anonymis√©es.

  ![image](https://github.com/jpbrasile/Teambot/assets/8331027/bde4c7f5-dc9a-4c86-a3bc-9d475a334f74)

**Bibliographie:**

[llm r√©duit ultra-rapide](https://huggingface.co/PowerInfer/TurboSparse-Mixtral): Une nouvelle m√©thode de rar√©faction bas√©e sur dReLU qui augmente la parcimonie du mod√®le √† 90 % tout en maintenant les performances, atteignant une acc√©l√©ration de 2 √† 5 fois lors de l'inf√©rence.

[agents s'am√©liorant avec le temps](https://arxiv.org/abs/2404.11964)

[Les agents intelligents serverless permettent d'automatiser et de g√©rer facilement des applications cloud sans avoir √† s'occuper des serveurs](https://github.com/ruvnet/agileagents)

[üîß Maestro est un cadre pour orchestrer intelligemment les sous-agents utilisant Claude Opus et d'autres mod√®les AI.
üîÑ Il supporte plusieurs mod√®les AI comme Opus, Haiku, GPT-4o, LMStudio, et Ollama.
üì¶ Les scripts sont organis√©s en fichiers distincts pour chaque fonctionnalit√© AI.
üåê Int√©gration d'une application Flask pour une interface utilisateur conviviale.](https://github.com/Doriandarko/maestro)

[Avec Sonnet 3.5 code avec web search and file management](https://github.com/Doriandarko/claude-engineer)

[Mille pages de data en m√©moire court terme (contexte 1 million tokens)[https://huggingface.co/spaces/Cyleux/Llama-3-8B-Instruct-Gradient-1048k)

[ $0.03 per hour of transcription](https://console.groq.com/playground?model=whisper-large-v3)

[Open Web UI](https://github.com/open-webui/open-webui) offre une interface utilisateur conviviale et extensible pour g√©rer des mod√®les de langage (LLM) en local, compatible avec les API d'OpenAI et Ollama. Il propose des fonctionnalit√©s avanc√©es telles que la prise en charge des plugins Python, la communication vocale/vid√©o, et la g√©n√©ration d'images, tout en √©tant accessible sur divers appareils.

[**MOOC pour se former aux agents (Autogen)**](https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/)

[Base](https://learn.deeplearning.ai/courses/ai-agentic-design-patterns-with-autogen/lesson/2/multi-agent-conversation-and-stand-up-comedy)

**27/06/2024**
- Il nous faut pouvoir modifier le programme Perplexica disponible sur Github
- [continue](https://github.com/continuedev/continue) peut analyser et adapter le programme

**28/06/2024**
... malheureusement _continue_ ne poss√®de pas d'API. Nous avons trouv√© une alternative: 

**R√©sum√© du besoin :**

Vous souhaitez automatiser l'utilisation de la commande @codebase de l'assistant de codage Continue, afin d'analyser automatiquement un r√©f√©rentiel entier de code. Vous cherchez une solution pour int√©grer cette fonctionnalit√© dans un programme Python.

**Proposition de solution :**

Bien que l'automatisation directe de @codebase via un programme Python ne soit pas une fonctionnalit√© standard de Continue, voici une approche alternative que vous pourriez envisager :
- Utilisez un script Python pour consolider tout le contenu du r√©f√©rentiel dans un seul fichier texte, en pr√©servant la structure des chemins de fichiers.
- Employez un mod√®le de langage large (LLM) avec une grande fen√™tre de contexte, comme DeepSeek Coder V2, qui peut traiter de grandes quantit√©s de code.
- Cr√©ez une interface en Python pour interagir avec le LLM, lui permettant d'analyser le fichier consolid√© et de r√©pondre √† des questions sur le code.
- Int√©grez un agent de recherche web pour compl√©ter les informations manquantes si n√©cessaire.
  
Cette approche vous permettrait d'obtenir une fonctionnalit√© similaire √† @codebase, mais de mani√®re automatis√©e et int√©gr√©e √† votre programme Python. Cela vous donnerait la flexibilit√© d'analyser l'ensemble du r√©f√©rentiel et d'interagir avec le code de mani√®re programmatique.

[Sonnet 3.5 donne le code](https://claude.ai/chat/aa8d87af-aa47-41ad-b364-d082ba649184)

Le fichier g√©n√©r√© est trop important pour √™tre exploit√©  par sonnet 3.5 et ChatGPTo. Nous t√©l√©chargeons deepseekcoder (contexte de 100 k) 

**29/06/2024**
- Abonnement √† Antropic pro afin d'avoir un fonctionneemnt de sonnet 3.5 optimal (200 k de contexte).
- R√©pertoire TeambotV1 cr√©e avec Perplexica fonctionnel 
- Nous avons relanc√© une adaptation de perplexica pour r√©cup√©rer les donn√©es en local avec succ√®s gr√¢ce √† [sonnet 3.5](https://claude.ai/chat/5a6553cd-6040-459d-98c5-d37b1dc359a5).

**30/06/2024**
- Je me suis abonn√© √† l'API antropic et j'ai r√©alis√© mon premier chat "helloworld.py avec bien s√ªr sonnet 3.5 qui m'a donn√© le code correspondant !
- Nous pouvons maintenant r√©cup√©rer les donn√©es sur n'importe quel sujet via le net et stocker ces informations localement. La taille de ces donn√©es peut d√©passer le contexte, je vais donc r√©aliser un RAG avec l'aide de Sonnet.

- R√©cup√©ration de donn√©es sur n'importe quel sujet via le web
- Stockage local des informations r√©cup√©r√©es
- Utilisation de Sonnet pour cr√©er une base de donn√©es questions-r√©ponses
- Mise en place d'un syst√®me RAG (Retrieval Augmented Generation) avec cette base de donn√©es
- Recherche de corr√©lation entre la question pos√©e et les questions stock√©es
- Possibilit√© d'utiliser la base de donn√©es pour l'alignement d'un LLM open source

Les principaux avantages de cette approche sont :
- Meilleure corr√©lation entre les questions et les r√©ponses par rapport √† un RAG traditionnel
- Base de connaissances personnalis√©e et sp√©cifique au domaine d'int√©r√™t
- Potentiel d'am√©lioration de la pr√©cision et de la pertinence des r√©ponses
- Flexibilit√© pour mettre √† jour et enrichir continuellement la base de donn√©es

Cependant, il faudra relever certains d√©fis :
- Complexit√© technique dans la mise en ≈ìuvre du syst√®me Sonnet
- Assurance de la qualit√© des paires questions-r√©ponses g√©n√©r√©es
- Gestion efficace de la base de donn√©es √† mesure qu'elle s'agrandit
- Mise en place d'un syst√®me d'√©valuation robuste pour mesurer l'efficacit√©

Cette approche innovante combine plusieurs technologies avanc√©es (RAG, Sonnet, alignement de LLM) pour potentiellement cr√©er un syst√®me plus performant et personnalis√©.
